{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maike\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\maike\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\maike\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "<ipython-input-1-f7e5547b1030>:9: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal #import alterado\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "import yfinance as yf\n",
    "from pandas.util.testing import assert_frame_equal #import alterado\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "\n",
    "    def __init__(self, state_size, action_space = 3, model_name = \"AITrader\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen = 2000)\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_final = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = self.model_builder()\n",
    "\n",
    "    def model_builder(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.Input(shape=(self.state_size,)))\n",
    "        model.add(tf.keras.layers.Dense(units = 32, activation = \"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(units = 64, activation = \"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(units = 128, activation = \"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(units = self.action_space, activation = \"linear\"))\n",
    "        model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(lr = 0.001))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def trade(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "\n",
    "        actions = self.model.predict(state)\n",
    "        return np.argmax(actions[0])\n",
    "\n",
    "\n",
    "    def batch_train(self, batch_size):  # sourcery skip: for-append-to-extend, list-comprehension\n",
    "        batch = []\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "            batch.append(self.memory[i])\n",
    "\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            if not done:\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "\n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_final:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def stocks_price_format(n):\n",
    "    return \"- $ {0:2f}\".format(abs(n)) if n < 0 else \"$ {0:2f}\".format(abs(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader(stock_name):\n",
    "    #dataset = data_reader.DataReader(stock_name, data_source = \"yahoo\")\n",
    "    dataset = yf.download(stock_name, start='2016-06-02')\n",
    "    start_date = str(dataset.index[0]).split()[0]\n",
    "    end_date = str(dataset.index[-1]).split()[0]\n",
    "    return dataset['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_creator(data, timestep, window_size):\n",
    "    # sourcery skip: for-append-to-extend, list-comprehension\n",
    "    starting_id = timestep - window_size + 1\n",
    "\n",
    "    if starting_id >= 0:\n",
    "        # windowed_data = data[starting_id:timestep + 1] # Atualizado 14/03/2022\n",
    "        windowed_data = np.array(data[starting_id:timestep + 1]) # Atualizado 14/03/2022\n",
    "    else:\n",
    "        # windowed_data = - starting_id * [data[0]] + list(data[0:timestep + 1]) # Atualizado 14/03/2022\n",
    "        windowed_data = np.array(- starting_id * [data[0]] + list(data[:timestep + 1]))\n",
    "\n",
    "    state = []\n",
    "    for i in range(window_size - 1):\n",
    "        state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\n",
    "\n",
    "    return np.array([state]), windowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 1000\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maike\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,171\n",
      "Trainable params: 11,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/1000\n",
      "AI Trader bought:  $ 24.430000\n",
      "AI Trader bought:  $ 24.480000\n",
      "AI Trader bought:  $ 24.657499\n",
      "AI Trader sold:  $ 24.757500  Profit: $ 0.327499\n",
      "AI Trader sold:  $ 24.735001  Profit: $ 0.255001\n",
      "AI Trader sold:  $ 24.912500  Profit: $ 0.255001\n",
      "AI Trader bought:  $ 24.387501\n",
      "AI Trader sold:  $ 23.832500  Profit: - $ 0.555000\n",
      "AI Trader bought:  $ 23.775000\n",
      "AI Trader bought:  $ 23.977501\n",
      "AI Trader sold:  $ 24.025000  Profit: $ 0.250000\n",
      "AI Trader bought:  $ 23.350000\n",
      "AI Trader bought:  $ 23.010000\n",
      "AI Trader sold:  $ 23.600000  Profit: - $ 0.377501\n",
      "AI Trader bought:  $ 23.900000\n",
      "AI Trader sold:  $ 23.972500  Profit: $ 0.622499\n",
      "AI Trader sold:  $ 23.747499  Profit: $ 0.737499\n",
      "AI Trader sold:  $ 23.882500  Profit: - $ 0.017500\n",
      "AI Trader bought:  $ 23.985001\n",
      "AI Trader sold:  $ 24.170000  Profit: $ 0.184999\n",
      "AI Trader bought:  $ 24.355000\n",
      "AI Trader sold:  $ 24.217501  Profit: - $ 0.137499\n",
      "AI Trader bought:  $ 24.697500\n",
      "AI Trader bought:  $ 24.695000\n",
      "AI Trader bought:  $ 24.967501\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1, 11\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9481062a6b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f68c8f07b721>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maike\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maike\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1656\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1, 11\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "for episode in range(1, episodes + 1):\n",
    "    print(f\"Episode: {episode}/{episodes}\")\n",
    "    state = state_creator(data, 0, window_size + 1)\n",
    "    total_profit = 0\n",
    "    trader.inventory = []\n",
    "    for t in range(data_samples):\n",
    "        action = trader.trade(state)\n",
    "        next_state = state_creator(data, t + 1, window_size + 1)\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1: # Comprando uma ação\n",
    "            trader.inventory.append(data[t])\n",
    "            print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "        elif action == 2 and len(trader.inventory) > 0: # Vendendo uma ação\n",
    "            buy_price = trader.inventory.pop(0)\n",
    "\n",
    "            reward = max(data[t] - buy_price, 0)\n",
    "            total_profit += data[t] - buy_price\n",
    "            print(\"AI Trader sold: \", stocks_price_format(data[t]), f\" Profit: {stocks_price_format(data[t] - buy_price)}\")\n",
    "\n",
    "\n",
    "        done = t == data_samples - 1\n",
    "        trader.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"########################\")\n",
    "            print(f\"Total profit: {total_profit}\")\n",
    "            print(\"########################\")\n",
    "\n",
    "        if len(trader.memory) > batch_size:\n",
    "            trader.batch_train(batch_size)\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        trader.model.save(f\"ai_trader_{episode}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.1.1\n",
      "ERROR: No matching distribution found for tensorflow==2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a5924eb46e62c1637fb675741deb95289fbde690b22e16bb7785772f131b920"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
